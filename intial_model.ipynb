{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz8LP62mC/hTzGu8Vle4rj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C23-PS435-bangkit/MachineLearning/blob/normal-dataset-only/intial_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libs"
      ],
      "metadata": {
        "id": "me6oML2PklmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uJzZqF4Dkt3X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TQN4Fe4mAyWj",
        "outputId": "1c2fe5fa-f4a6-4d7d-e288-0c65e6d17aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Split Datasets"
      ],
      "metadata": {
        "id": "8XGjuWNYkqh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the datasets"
      ],
      "metadata": {
        "id": "o1Jee5iRKc_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset'\n",
        "\n",
        "bd_dir = os.path.join(base_dir, 'bacterial_dermatosis')\n",
        "fi_dir = os.path.join(base_dir, 'fungal_infection')\n",
        "ha_dir = os.path.join(base_dir, 'hypersensitivity_allergic_dermatosis')\n",
        "he_dir = os.path.join(base_dir, 'healthy')\n",
        "\n",
        "print('total training bacterial_dermatosis images:', len(os.listdir(bd_dir)))\n",
        "print('total training fungal_infection images:', len(os.listdir(fi_dir)))\n",
        "print('total training hypersensitivity_allergic_dermatosis images:', len(os.listdir(ha_dir)))\n",
        "print('total training healthy images:', len(os.listdir(he_dir)))\n",
        "\n",
        "bd_files = os.listdir(bd_dir)\n",
        "print(bd_files[:10])\n",
        "\n",
        "fi_files = os.listdir(fi_dir)\n",
        "print(fi_files[:10])\n",
        "\n",
        "ha_files = os.listdir(ha_dir)\n",
        "print(ha_files[:10])\n",
        "\n",
        "he_files = os.listdir(he_dir)\n",
        "print(he_files[:10])"
      ],
      "metadata": {
        "id": "3s9Oe0YOC9zr",
        "outputId": "3b31715c-a5c1-43a7-fc84-6adf34769d26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training bacterial_dermatosis images: 12\n",
            "total training fungal_infection images: 11\n",
            "total training hypersensitivity_allergic_dermatosis images: 13\n",
            "total training healthy images: 26\n",
            "['dog210612_03_01_13_pic0.jpg', 'dog210617_00_02_02_pic0.jpg', 'dog210615_01_02_06_pic0.jpg', 'Dog210619_01_01_44_pic0.jpg', 'Dog210624_08_02_35_pic0.jpg', 'Dog210628_04_01_17_pic0.jpg', 'Dog210628_11_01_16_pic0.jpg', 'Dog210629_09_02_13_pic0.jpg', 'Dog210630_04_02_11_pic0.jpg', 'Dog210702_09_01_09_pic0.jpg']\n",
            "['dog210422_04_02_33_pic0.jpg', 'dog210424_09_02_32_pic0.jpg', 'dog210430_05_01_29_pic0.jpg', 'dog210430_08_01_30_pic0.jpg', 'dog210504_49_01_28_pic0.jpg', 'dog210610_04_02_14_pic0.jpg', 'dog210610_48_02_15_pic0.jpg', 'Dog210622_03_02_41_pic0.jpg', 'Dog210623_08_02_37_pic0.jpg', 'Dog210706_01_02_06_pic0.jpg']\n",
            "['dog210424_05_01_31_pic0.jpg', 'dog210612_48_02_12_pic0.jpg', 'dog210617_02_02_01_pic0.jpg', 'dog210617_01_02_05_pic0.jpg', 'Dog210621_01_01_43_pic0.jpg', 'Dog210622_01_01_39_pic0.jpg', 'Dog210623_05_01_38_pic0.jpg', 'Dog210624_01_02_36_pic0.jpg', 'Dog210624_12_02_32_pic0.jpg', 'Dog210625_05_02_30_pic0.jpg']\n",
            "['dog210505_01_02_26_pic0.jpg', 'dog210505_01_02_25_pic0.jpg', 'dog210505_01_02_27_pic0.jpg', 'dog210508_06_02_19_pic0.jpg', 'dog210508_06_02_18_pic0.jpg', 'dog210508_06_02_20_pic0.jpg', 'dog210508_07_02_21_pic0.jpg', 'dog210508_07_02_22_pic0.jpg', 'dog210508_07_02_23_pic0.jpg', 'dog210511_05_02_17_pic0.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged'\n",
        "\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "def create_train_val_dirs(root_path):\n",
        "\n",
        "  # List of labels\n",
        "  labels = ['bd', 'fi', 'ha', 'he']\n",
        "\n",
        "  # Create train directory\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  os.makedirs(train_dir, exist_ok=True)\n",
        "\n",
        "  for label in labels:\n",
        "      label_dir = os.path.join(train_dir, label)\n",
        "      os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "  # Create validation directory\n",
        "  val_dir = os.path.join(root_path, 'validation')\n",
        "  os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "  for label in labels:\n",
        "      label_dir = os.path.join(val_dir, label)\n",
        "      os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"Error\")"
      ],
      "metadata": {
        "id": "EXnIKlmPkKZe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "id": "Y7uAobW1ly2y",
        "outputId": "6a8c76f7-9143-449b-c188-0475d950b637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training/bd\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training/fi\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training/ha\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training/he\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation/bd\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation/fi\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation/ha\n",
            "/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation/he\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try to Crop"
      ],
      "metadata": {
        "id": "lcCduGe3LO6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to crop image\n",
        "# note: the amount of croped pixels were approxed by me (nopal) \n",
        "#       by measure the excess pixels\n",
        "def crop_image(image):\n",
        "    crop_width = 1920 - 170 - 150  # Calculate the resulting width after trimming\n",
        "    crop_height = 1080  # Height remains the same\n",
        "    crop_location = (170, 0)  # Starting position of the crop\n",
        "\n",
        "    # Crop the image using array indexing\n",
        "    cropped_image = image[crop_location[1]:crop_location[1] + crop_height,\n",
        "                          crop_location[0]:crop_location[0] + crop_width, :]\n",
        "\n",
        "    return cropped_image"
      ],
      "metadata": {
        "id": "3F37ph3xZkgf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to split dataset into training and validation\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "    files = os.listdir(SOURCE_DIR)\n",
        "\n",
        "    verified_files = []\n",
        "    for file in files:\n",
        "        if os.path.getsize(os.path.join(SOURCE_DIR, file)) == 0:\n",
        "            print(f\"{file} is zero length, so ignoring.\")\n",
        "        else:\n",
        "            verified_files.append(file)\n",
        "\n",
        "    # Shuffle the files\n",
        "    random.shuffle(verified_files)\n",
        "\n",
        "    # Calculate the split index\n",
        "    split_idx = int(SPLIT_SIZE * len(verified_files))\n",
        "\n",
        "    # Split the files\n",
        "    train_files = verified_files[:split_idx]\n",
        "    val_files = verified_files[split_idx:]\n",
        "\n",
        "    # Copy train files\n",
        "    for file in train_files:\n",
        "        src_path = os.path.join(SOURCE_DIR, file)\n",
        "        dst_path = os.path.join(TRAINING_DIR, file)\n",
        "        # Load the image using TensorFlow\n",
        "        image = tf.io.read_file(src_path)\n",
        "        image = tf.image.decode_image(image)\n",
        "        # Crop the image\n",
        "        cropped_image = crop_image(image)\n",
        "        # Save the cropped image to the destination directory\n",
        "        tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))\n",
        "\n",
        "    # Copy validation files\n",
        "    for file in val_files:\n",
        "        src_path = os.path.join(SOURCE_DIR, file)\n",
        "        dst_path = os.path.join(VALIDATION_DIR, file)\n",
        "        # Load the image using TensorFlow\n",
        "        image = tf.io.read_file(src_path)\n",
        "        image = tf.image.decode_image(image)\n",
        "        # Crop the image\n",
        "        cropped_image = crop_image(image)\n",
        "        # Save the cropped image to the destination directory\n",
        "        tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))"
      ],
      "metadata": {
        "id": "8mLeyYK9Kh35"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/training\"\n",
        "VALIDATION_DIR = \"/content/drive/MyDrive/Datasets/Bangkit - Capstone/normal dataset/arranged/validation\"\n",
        "\n",
        "LABELS = ['bd', 'fi', 'ha', 'he']\n",
        "\n",
        "TRAINING_LABEL_DIRS = [os.path.join(TRAINING_DIR, label) for label in LABELS]\n",
        "VALIDATION_LABEL_DIRS = [os.path.join(VALIDATION_DIR, label) for label in LABELS]\n",
        "\n",
        "# Empty directories in case this cell runs multiple times\n",
        "for label_dir in TRAINING_LABEL_DIRS:\n",
        "    if len(os.listdir(label_dir)) > 0:\n",
        "        for file in os.scandir(label_dir):\n",
        "            os.remove(file.path)\n",
        "\n",
        "for label_dir in VALIDATION_LABEL_DIRS:\n",
        "    if len(os.listdir(label_dir)) > 0:\n",
        "        for file in os.scandir(label_dir):\n",
        "            os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = 0.8\n",
        "\n",
        "# Run the function\n",
        "for label in LABELS:\n",
        "    source_dir = eval(f'{label}_dir')\n",
        "    train_dir = os.path.join(TRAINING_DIR, label)\n",
        "    val_dir = os.path.join(VALIDATION_DIR, label)\n",
        "    split_data(source_dir, train_dir, val_dir, split_size)\n",
        "\n",
        "# Check the number of images in each directory\n",
        "\n",
        "# Original source directories should contain unchanged images\n",
        "for label in LABELS:\n",
        "    source_dir = eval(f'{label}_dir')\n",
        "    print(f\"Original {label}'s directory has {len(os.listdir(source_dir))} images\")\n",
        "\n",
        "# Training and validation splits\n",
        "for i, label in enumerate(LABELS):\n",
        "    print(f\"There are {len(os.listdir(TRAINING_LABEL_DIRS[i]))} images of {label} for training\")\n",
        "    print(f\"There are {len(os.listdir(VALIDATION_LABEL_DIRS[i]))} images of {label} for validation\")"
      ],
      "metadata": {
        "id": "4UFcjWlHrBq1",
        "outputId": "ce2b1008-fa64-4f5a-d907-8a81bb84b990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original bd's directory has 12 images\n",
            "Original fi's directory has 11 images\n",
            "Original ha's directory has 13 images\n",
            "Original he's directory has 26 images\n",
            "There are 9 images of bd for training\n",
            "There are 3 images of bd for validation\n",
            "There are 8 images of fi for training\n",
            "There are 3 images of fi for validation\n",
            "There are 10 images of ha for training\n",
            "There are 3 images of ha for validation\n",
            "There are 20 images of he for training\n",
            "There are 6 images of he for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Data Generator"
      ],
      "metadata": {
        "id": "LCm1Ul4OtNT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class and set the desired augmentation parameters\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1.0/255.,\n",
        "      shear_range=0.2,\n",
        "      rotation_range=360,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "  )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      directory=TRAINING_DIR,\n",
        "      batch_size=10,\n",
        "      class_mode='categorical',\n",
        "      target_size=(128, 128)\n",
        "  )\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class and set the rescale parameter\n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      directory=VALIDATION_DIR,\n",
        "      batch_size=10,\n",
        "      class_mode='categorical',\n",
        "      target_size=(128, 128)\n",
        "  )\n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "E4zIT3zmsVnC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "metadata": {
        "id": "MMksZeRoCwUH",
        "outputId": "3b7ff462-1ced-427b-ee10-65f3b2aa4725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47 images belonging to 4 classes.\n",
            "Found 15 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Using Restnet"
      ],
      "metadata": {
        "id": "J5dfsgUoE15Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
      ],
      "metadata": {
        "id": "p43i5JKJJcBT",
        "outputId": "98e40ff2-3aa7-430f-a6f0-0c70ee3ff62f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Create a new model by adding your own classifier on top of the pre-trained ResNet model\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "Q1Ekw5piJiad"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "O_QhE1B5JsKm",
        "outputId": "b3b44ca1-aed3-4a27-8cc1-7a9b6c0a55e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 46s 5s/step - loss: 8.5143 - accuracy: 0.2766 - val_loss: 15.3162 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 8.8929 - accuracy: 0.1489 - val_loss: 1868.3269 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 7.1826 - accuracy: 0.3617 - val_loss: 822454.6250 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 5.7973 - accuracy: 0.3830 - val_loss: 2531844.0000 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 20s 4s/step - loss: 3.6505 - accuracy: 0.4043 - val_loss: 20459708.0000 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 6.4210 - accuracy: 0.4468 - val_loss: 9382912.0000 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 20s 4s/step - loss: 2.6669 - accuracy: 0.4681 - val_loss: 1328487.7500 - val_accuracy: 0.2000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 20s 4s/step - loss: 2.5596 - accuracy: 0.4043 - val_loss: 2256.4392 - val_accuracy: 0.2000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 3.0563 - accuracy: 0.4255 - val_loss: 396.8612 - val_accuracy: 0.2000\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 21s 4s/step - loss: 3.5707 - accuracy: 0.4894 - val_loss: 87.5492 - val_accuracy: 0.2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "VoYIL11bEu-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([ \n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss=tf.keras.losses.binary_crossentropy,\n",
        "                metrics=['accuracy']) \n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "e83EyCP3DE6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "gu69sMw2DtuR",
        "outputId": "d3d7f092-9a60-4b44-8017-57cca80f9b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.5686 - accuracy: 0.3972 - val_loss: 0.5436 - val_accuracy: 0.4160\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 93s 2s/step - loss: 0.5454 - accuracy: 0.4194 - val_loss: 0.5413 - val_accuracy: 0.4160\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.5435 - accuracy: 0.4194 - val_loss: 0.5408 - val_accuracy: 0.4160\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.5421 - accuracy: 0.4194 - val_loss: 0.5398 - val_accuracy: 0.4160\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 75s 1s/step - loss: 0.5420 - accuracy: 0.4194 - val_loss: 0.5401 - val_accuracy: 0.4160\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.5408 - accuracy: 0.4194 - val_loss: 0.5407 - val_accuracy: 0.4160\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.5420 - accuracy: 0.4194 - val_loss: 0.5392 - val_accuracy: 0.4160\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.5411 - accuracy: 0.4194 - val_loss: 0.5394 - val_accuracy: 0.4160\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.5411 - accuracy: 0.4194 - val_loss: 0.5402 - val_accuracy: 0.4160\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.5416 - accuracy: 0.4194 - val_loss: 0.5399 - val_accuracy: 0.4160\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 75s 1s/step - loss: 0.5410 - accuracy: 0.4194 - val_loss: 0.5400 - val_accuracy: 0.4160\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.5410 - accuracy: 0.4194 - val_loss: 0.5395 - val_accuracy: 0.4160\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.5405 - accuracy: 0.4194 - val_loss: 0.5396 - val_accuracy: 0.4160\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.5420 - accuracy: 0.4194 - val_loss: 0.5404 - val_accuracy: 0.4160\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.5403 - accuracy: 0.4194 - val_loss: 0.5486 - val_accuracy: 0.4160\n",
            "Epoch 16/100\n",
            "40/50 [=======================>......] - ETA: 12s - loss: 0.5428 - accuracy: 0.4141"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bdec714a1ef8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try to crop"
      ],
      "metadata": {
        "id": "DogHZQ3MGnwY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNjBfGgFE1UJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}