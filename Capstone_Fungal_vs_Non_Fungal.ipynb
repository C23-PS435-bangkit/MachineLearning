{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN3wkGqIJxYWba2sRZyK0pp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C23-PS435-bangkit/MachineLearning/blob/haah/Capstone_Fungal_vs_Non_Fungal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D9HFraDGPSPk"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/images_fungal.zip'  # Replace with the actual path to your uploaded zip file\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/extracted')  # Specify the destination directory to extract to"
      ],
      "metadata": {
        "id": "JUWD4_dJWIrD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJuUpgQCRR1d",
        "outputId": "fa544fa7-1f6c-4ad6-edc5-eb84e26c77fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "source_path = '/content/drive/MyDrive/Capstone/Fungal V Non-Fungal'\n",
        "\n",
        "source_path_fungal = os.path.join(source_path, 'images_fungal')\n",
        "source_path_non_fungal = os.path.join(source_path, 'non_fungal')\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_fungal))} images of Fungal Infection.\")\n",
        "print(f\"There are {len(os.listdir(source_path_non_fungal))} images of Non Fungal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT-ZOxkQYPON",
        "outputId": "1bce7c2a-93ea-4be9-90fa-97d144b138c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 88 images of Fungal Infection.\n",
            "There are 51 images of Non Fungal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define root directory\n",
        "root_dir = '/content/drive/MyDrive/Capstone/mencoba'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# GRADED FUNCTION: create_train_val_dirs\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "  \n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "  \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  os.makedirs(root_path)\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  val_dir = os.path.join(root_path, 'validation')\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "\n",
        "  train_cats_dir = os.path.join(train_dir, 'fungal')\n",
        "  train_dogs_dir = os.path.join(train_dir, 'nonfung')\n",
        "  val_cats_dir = os.path.join(val_dir, 'fungal')\n",
        "  val_dogs_dir = os.path.join(val_dir, 'nonfung')\n",
        "\n",
        "  os.makedirs(train_cats_dir)\n",
        "  os.makedirs(train_dogs_dir)\n",
        "  os.makedirs(val_cats_dir)\n",
        "  os.makedirs(val_dogs_dir)\n",
        "\n",
        "  pass\n",
        "  \n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "1PAkT7ZPTOhA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your create_train_val_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60NkMtn-TtSH",
        "outputId": "bfa9ce50-ed48-4f0b-d8d6-132f2a563117"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Capstone/mencoba/training\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation\n",
            "/content/drive/MyDrive/Capstone/mencoba/training/fungal\n",
            "/content/drive/MyDrive/Capstone/mencoba/training/nonfung\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation/fungal\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation/nonfung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to crop image\n",
        "# # note: the amount of croped pixels were approxed by me (nopal) \n",
        "# #       by measure the excess pixels\n",
        "# def crop_image(image):\n",
        "#     crop_width = 1920 - 170 - 160  # Calculate the resulting width after trimming\n",
        "#     crop_height = 1080  # Height remains the same\n",
        "#     crop_location = (170, 0)  # Starting position of the crop\n",
        "#     cropped_image = tf.image.crop(image, crop_location, [crop_height, crop_width])\n",
        "#     return cropped_image"
      ],
      "metadata": {
        "id": "p-M8YyTUZc21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def crop_image(image):\n",
        "#     crop_width = 1920 - 170 - 150  # Calculate the resulting width after trimming\n",
        "#     crop_height = 1080  # Height remains the same\n",
        "#     crop_location = (170, 0)  # Starting position of the crop\n",
        "\n",
        "#     # Crop the image using array indexing\n",
        "#     cropped_image = image[crop_location[1]:crop_location[1] + crop_height,\n",
        "#                           crop_location[0]:crop_location[0] + crop_width, :]\n",
        "\n",
        "#     return cropped_image"
      ],
      "metadata": {
        "id": "V18qe6fFZhGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to split dataset into training and validation\n",
        "# def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "#     files = os.listdir(SOURCE_DIR)\n",
        "\n",
        "#     verified_files = []\n",
        "#     for file in files:\n",
        "#         if os.path.getsize(os.path.join(SOURCE_DIR, file)) == 0:\n",
        "#             print(f\"{file} is zero length, so ignoring.\")\n",
        "#         else:\n",
        "#             verified_files.append(file)\n",
        "\n",
        "#     # Shuffle the files\n",
        "#     random.shuffle(verified_files)\n",
        "\n",
        "#     # Calculate the split index\n",
        "#     split_idx = int(SPLIT_SIZE * len(verified_files))\n",
        "\n",
        "#     # Split the files\n",
        "#     train_files = verified_files[:split_idx]\n",
        "#     val_files = verified_files[split_idx:]\n",
        "\n",
        "#     # Copy train files\n",
        "#     for file in train_files:\n",
        "#         src_path = os.path.join(SOURCE_DIR, file)\n",
        "#         dst_path = os.path.join(TRAINING_DIR, file)\n",
        "#         # Load the image using TensorFlow\n",
        "#         image = tf.io.read_file(src_path)\n",
        "#         image = tf.image.decode_image(image)\n",
        "#         # Crop the image\n",
        "#         cropped_image = crop_image(image)\n",
        "#         # Save the cropped image to the destination directory\n",
        "#         tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))\n",
        "\n",
        "#     # Copy validation files\n",
        "#     for file in val_files:\n",
        "#         src_path = os.path.join(SOURCE_DIR, file)\n",
        "#         dst_path = os.path.join(VALIDATION_DIR, file)\n",
        "#         # Load the image using TensorFlow\n",
        "#         image = tf.io.read_file(src_path)\n",
        "#         image = tf.image.decode_image(image)\n",
        "#         # Crop the image\n",
        "#         cropped_image = crop_image(image)\n",
        "#         # Save the cropped image to the destination directory\n",
        "#         tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))"
      ],
      "metadata": {
        "id": "r9fFDRIIZtrj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  ### START CODE HERE\n",
        "  file_list = []\n",
        "\n",
        "\n",
        "  for file in os.listdir(SOURCE_DIR):\n",
        "    file_path = os.path.join(SOURCE_DIR,file)\n",
        "    if(os.path.getsize(file_path) == 0):\n",
        "      print(file + \" is zero length, so ignoring.\")\n",
        "    else:\n",
        "      file_list.append(file_path)\n",
        "\n",
        "  train_num_items = int(round(len(file_list) * SPLIT_SIZE, 0))\n",
        "  train_list = random.sample(file_list, train_num_items)\n",
        "  val_list = list(set(file_list) - set(train_list))\n",
        "\n",
        "  for f in train_list:\n",
        "    copyfile(f,TRAINING_DIR+os.path.basename(f))\n",
        "  for f in val_list:\n",
        "    copyfile(f,VALIDATION_DIR+os.path.basename(f))\n",
        "\n",
        "  pass\n",
        "\n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "9oHwLZUxT3C8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "CAT_SOURCE_DIR = \"/content/drive/MyDrive/Capstone/Fungal V Non-Fungal/images_fungal\"\n",
        "DOG_SOURCE_DIR = \"/content/drive/MyDrive/Capstone/Fungal V Non-Fungal/non_fungal\"\n",
        "\n",
        "TRAINING_DIR = \"/content/drive/MyDrive/Capstone/mencoba/training\"\n",
        "VALIDATION_DIR = \"/content/drive/MyDrive/Capstone/mencoba/validation\"\n",
        "\n",
        "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"fungal/\")\n",
        "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"fungal/\")\n",
        "\n",
        "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"nonfung/\")\n",
        "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"nonfung/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .8\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal fungal directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
        "print(f\"Original healthy directory has {len(DOG_SOURCE_DIR)} images\\n\")\n",
        "\n",
        "# Training and validation splits\n",
        "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of fungal for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of healthy for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of fungal for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of healthy for validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taJ9ykn9T5JX",
        "outputId": "176934b9-5d3a-4cd4-ea65-54d7a83cc3e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original fungal directory has 88 images\n",
            "Original healthy directory has 62 images\n",
            "\n",
            "There are 70 images of fungal for training\n",
            "There are 41 images of healthy for training\n",
            "There are 18 images of fungal for validation\n",
            "There are 10 images of healthy for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  train_datagen = ImageDataGenerator(    \n",
        "    rescale=1.0/255.)\n",
        "    # rotation_range=10,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # shear_range=0.1,\n",
        "    # zoom_range=0.1,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode='nearest')\n",
        "    # rescale=1.0/255,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=16,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(128, 128))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.)\n",
        "    # rotation_range=10,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # shear_range=0.1,\n",
        "    # zoom_range=0.1,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(128, 128))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "sBZN_JC_UnKM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPl2qpS4Uqkv",
        "outputId": "e53237ab-6703-46af-d3a6-9d5f6c7b1516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 111 images belonging to 2 classes.\n",
            "Found 28 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ba844313",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>=0.97):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2), \n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(), \n",
        "      # 512 neuron hidden layer\n",
        "      tf.keras.layers.Dense(512, activation='relu'), \n",
        "      # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cxOHZQipUuvE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRDa7-8I7Jhu",
        "outputId": "7ac9399c-820e-4a68-b29d-f19dcfafc696"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 126, 126, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 63, 63, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 61, 61, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 30, 30, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               2359808   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,457,761\n",
            "Trainable params: 2,457,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take a few epochs)\n",
        "model = create_model()\n",
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 50,\n",
        "                    verbose = 2,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-esmAoZ33c7",
        "outputId": "06330ffd-7b46-483b-b176-992509bdf92b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 - 9s - loss: 0.6790 - accuracy: 0.5766 - val_loss: 0.6425 - val_accuracy: 0.6429 - 9s/epoch - 1s/step\n",
            "Epoch 2/50\n",
            "7/7 - 5s - loss: 0.5700 - accuracy: 0.6306 - val_loss: 0.4909 - val_accuracy: 0.6071 - 5s/epoch - 769ms/step\n",
            "Epoch 3/50\n",
            "7/7 - 6s - loss: 0.4428 - accuracy: 0.7387 - val_loss: 0.3818 - val_accuracy: 0.8214 - 6s/epoch - 892ms/step\n",
            "Epoch 4/50\n",
            "7/7 - 5s - loss: 0.3740 - accuracy: 0.8198 - val_loss: 0.3918 - val_accuracy: 0.7500 - 5s/epoch - 748ms/step\n",
            "Epoch 5/50\n",
            "7/7 - 6s - loss: 0.3230 - accuracy: 0.8288 - val_loss: 0.2945 - val_accuracy: 0.8929 - 6s/epoch - 924ms/step\n",
            "Epoch 6/50\n",
            "7/7 - 5s - loss: 0.2454 - accuracy: 0.9279 - val_loss: 0.2909 - val_accuracy: 0.8929 - 5s/epoch - 753ms/step\n",
            "Epoch 7/50\n",
            "7/7 - 6s - loss: 0.2262 - accuracy: 0.9369 - val_loss: 0.2881 - val_accuracy: 0.8929 - 6s/epoch - 896ms/step\n",
            "Epoch 8/50\n",
            "7/7 - 5s - loss: 0.2009 - accuracy: 0.9279 - val_loss: 0.3067 - val_accuracy: 0.8929 - 5s/epoch - 741ms/step\n",
            "Epoch 9/50\n",
            "7/7 - 6s - loss: 0.2116 - accuracy: 0.9459 - val_loss: 0.2935 - val_accuracy: 0.8929 - 6s/epoch - 925ms/step\n",
            "Epoch 10/50\n",
            "7/7 - 5s - loss: 0.1906 - accuracy: 0.9459 - val_loss: 0.2774 - val_accuracy: 0.8929 - 5s/epoch - 759ms/step\n",
            "Epoch 11/50\n",
            "7/7 - 7s - loss: 0.1888 - accuracy: 0.9459 - val_loss: 0.2951 - val_accuracy: 0.8929 - 7s/epoch - 1s/step\n",
            "Epoch 12/50\n",
            "7/7 - 5s - loss: 0.1752 - accuracy: 0.9459 - val_loss: 0.3136 - val_accuracy: 0.8929 - 5s/epoch - 747ms/step\n",
            "Epoch 13/50\n",
            "7/7 - 7s - loss: 0.1641 - accuracy: 0.9459 - val_loss: 0.3058 - val_accuracy: 0.8571 - 7s/epoch - 962ms/step\n",
            "Epoch 14/50\n",
            "7/7 - 6s - loss: 0.1853 - accuracy: 0.9279 - val_loss: 0.3639 - val_accuracy: 0.8929 - 6s/epoch - 811ms/step\n",
            "Epoch 15/50\n",
            "7/7 - 6s - loss: 0.2093 - accuracy: 0.9189 - val_loss: 0.4077 - val_accuracy: 0.7143 - 6s/epoch - 919ms/step\n",
            "Epoch 16/50\n",
            "7/7 - 5s - loss: 0.1667 - accuracy: 0.9279 - val_loss: 0.3294 - val_accuracy: 0.8929 - 5s/epoch - 748ms/step\n",
            "Epoch 17/50\n",
            "7/7 - 5s - loss: 0.1527 - accuracy: 0.9459 - val_loss: 0.3412 - val_accuracy: 0.8571 - 5s/epoch - 760ms/step\n",
            "Epoch 18/50\n",
            "7/7 - 6s - loss: 0.1453 - accuracy: 0.9459 - val_loss: 0.3288 - val_accuracy: 0.8929 - 6s/epoch - 801ms/step\n",
            "Epoch 19/50\n",
            "7/7 - 6s - loss: 0.1397 - accuracy: 0.9459 - val_loss: 0.3388 - val_accuracy: 0.8214 - 6s/epoch - 894ms/step\n",
            "Epoch 20/50\n",
            "7/7 - 5s - loss: 0.1155 - accuracy: 0.9550 - val_loss: 0.3713 - val_accuracy: 0.8929 - 5s/epoch - 747ms/step\n",
            "Epoch 21/50\n",
            "7/7 - 6s - loss: 0.1127 - accuracy: 0.9550 - val_loss: 0.3972 - val_accuracy: 0.8571 - 6s/epoch - 921ms/step\n",
            "Epoch 22/50\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "7/7 - 5s - loss: 0.1077 - accuracy: 0.9730 - val_loss: 0.4610 - val_accuracy: 0.8929 - 5s/epoch - 743ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracies for each epoch\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "5PHrd-Sq8g8N",
        "outputId": "54f2805c-4e74-4501-d971-d1c9b8b2d4db"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Save the trained model as a Keras HDF5 file. \n",
        "\n",
        "saved_model_path = \"./my_model.h5\"\n",
        "model.save(saved_model_path)\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "qadL93Qt86EP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Use the tensorflow.js converter to convert the saved Keras model into JSON format.\n",
        "!pip install tensorflow==2.2\n",
        "!pip install tensorflowjs\n",
        "import tensorflow as tf\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)\n",
        "# YOUR CODE HERE\n",
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nybrj_K89EKA",
        "outputId": "ff98166d-35c3-45b4-ffc4-591f74589407"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.2 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.2\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.6.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax<0.6.3,>=0.6.2 (from tensorflowjs)\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m189.9/189.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (5.12.0)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.10)\n",
            "Requirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.12.0)\n",
            "Collecting tensorflow-decision-forests>=1.3.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.13.0)\n",
            "Collecting packaging~=20.9 (from tensorflowjs)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.36)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (13.3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (6.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (1.5.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.3.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, packaging, flax, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.6.9\n",
            "    Uninstalling flax-0.6.9:\n",
            "      Successfully uninstalled flax-0.6.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flax-0.6.2 packaging-20.9 tensorflow-decision-forests-1.3.0 tensorflowjs-4.6.0 wurlitzer-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using TensorFlow Version: 2.12.0\n",
            "2023-06-09 16:20:30.375042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2), \n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(), \n",
        "      # 512 neuron hidden layer\n",
        "      tf.keras.layers.Dense(512, activation='relu'), \n",
        "      # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "68U-dL_HERVn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRXSZ4WpE5EW",
        "outputId": "abbf4235-62f7-4f64-c679-640bc8b63bd4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.8026 - accuracy: 0.5946 - val_loss: 0.6582 - val_accuracy: 0.6429\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.6211 - accuracy: 0.6396 - val_loss: 0.5448 - val_accuracy: 0.7857\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.5450 - accuracy: 0.7748 - val_loss: 0.4371 - val_accuracy: 0.7500\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.4557 - accuracy: 0.8378 - val_loss: 0.3937 - val_accuracy: 0.8214\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.3216 - accuracy: 0.8919 - val_loss: 0.5124 - val_accuracy: 0.6429\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.3540 - accuracy: 0.8378 - val_loss: 0.4324 - val_accuracy: 0.7500\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.3335 - accuracy: 0.8739 - val_loss: 0.3482 - val_accuracy: 0.8214\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2386 - accuracy: 0.9279 - val_loss: 0.3469 - val_accuracy: 0.8571\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.2708 - accuracy: 0.9099 - val_loss: 0.3518 - val_accuracy: 0.8571\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.4505 - val_accuracy: 0.8571\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2214 - accuracy: 0.9369 - val_loss: 0.5110 - val_accuracy: 0.8571\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2201 - accuracy: 0.9189 - val_loss: 0.3937 - val_accuracy: 0.8571\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.1876 - accuracy: 0.9459 - val_loss: 0.4983 - val_accuracy: 0.8571\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2102 - accuracy: 0.9369 - val_loss: 0.3802 - val_accuracy: 0.8571\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1586 - accuracy: 0.9459 - val_loss: 0.5912 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
      ],
      "metadata": {
        "id": "w_bQusmoWM1h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Create a new model by adding your own classifier on top of the pre-trained ResNet model\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "AQciyQCZWVg7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "LuZQ6-HjWcmR",
        "outputId": "3f7964a7-520f-4058-fb36-fa2cac03a243"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 70s 7s/step - loss: 2.0308 - accuracy: 0.6937 - val_loss: 2025.8903 - val_accuracy: 0.6429\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 44s 6s/step - loss: 0.2158 - accuracy: 0.9189 - val_loss: 143049.0156 - val_accuracy: 0.6429\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 43s 6s/step - loss: 0.2387 - accuracy: 0.9459 - val_loss: 532021.9375 - val_accuracy: 0.6429\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 47s 7s/step - loss: 0.1038 - accuracy: 0.9640 - val_loss: 515740.7812 - val_accuracy: 0.6429\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 44s 6s/step - loss: 0.1261 - accuracy: 0.9910 - val_loss: 254101.0938 - val_accuracy: 0.6429\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 46s 6s/step - loss: 0.2518 - accuracy: 0.9459 - val_loss: 105589.9453 - val_accuracy: 0.6429\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9910"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f1e6b0f8bc58>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Initialize the Pretrained Model\n",
        "feature_extractor = ResNet50(weights='imagenet', \n",
        "                             input_shape=(128, 128, 3),\n",
        "                             include_top=False)\n",
        "\n",
        "# Set this parameter to make sure it's not being trained\n",
        "feature_extractor.trainable = False\n",
        "\n",
        "# Set the input layer\n",
        "input_ = tf.keras.Input(shape=(128, 128, 3))\n",
        "\n",
        "# Set the feature extractor layer\n",
        "x = feature_extractor(input_, training=False)\n",
        "\n",
        "# Set the pooling layer\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Set the final layer with sigmoid activation function\n",
        "output_ = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model object\n",
        "model = tf.keras.Model(input_, output_)\n",
        "\n",
        "# Compile it\n",
        "model.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Print The Summary of The Model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edlbXJQLG9g4",
        "outputId": "47dce562-0008-4e0c-caf6-cfd9350d87e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,589,761\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs=15, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L_WcSk1HOag",
        "outputId": "583d0d00-16d7-43dc-de75-bed125dec38a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - 20s 2s/step - loss: 0.7754 - accuracy: 0.3694 - val_loss: 0.7306 - val_accuracy: 0.3571\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.7080 - accuracy: 0.4234 - val_loss: 0.6729 - val_accuracy: 0.6429\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 16s 2s/step - loss: 0.6656 - accuracy: 0.6306 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6527 - accuracy: 0.6306 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6509 - accuracy: 0.6306 - val_loss: 0.6445 - val_accuracy: 0.6429\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6506 - accuracy: 0.6306 - val_loss: 0.6429 - val_accuracy: 0.6429\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6466 - accuracy: 0.6306 - val_loss: 0.6403 - val_accuracy: 0.6429\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 18s 2s/step - loss: 0.6428 - accuracy: 0.6306 - val_loss: 0.6383 - val_accuracy: 0.6429\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6401 - accuracy: 0.6306 - val_loss: 0.6370 - val_accuracy: 0.6429\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6382 - accuracy: 0.6306 - val_loss: 0.6361 - val_accuracy: 0.6429\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 17s 2s/step - loss: 0.6345 - accuracy: 0.6306 - val_loss: 0.6336 - val_accuracy: 0.6429\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6319 - accuracy: 0.6306 - val_loss: 0.6311 - val_accuracy: 0.6429\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 17s 2s/step - loss: 0.6293 - accuracy: 0.6306 - val_loss: 0.6295 - val_accuracy: 0.6429\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 16s 2s/step - loss: 0.6257 - accuracy: 0.6306 - val_loss: 0.6273 - val_accuracy: 0.6429\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6234 - accuracy: 0.6306 - val_loss: 0.6250 - val_accuracy: 0.6429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f806a683040>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}