{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9HFraDGPSPk"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/images_fungal.zip'  # Replace with the actual path to your uploaded zip file\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/extracted')  # Specify the destination directory to extract to"
      ],
      "metadata": {
        "id": "JUWD4_dJWIrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJuUpgQCRR1d",
        "outputId": "4545f6b8-f457-40fb-c50b-7e45aa60adc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "source_path = '/content/drive/MyDrive/Capstone/Fungal V Non-Fungal'\n",
        "\n",
        "source_path_fungal = os.path.join(source_path, 'images_fungal')\n",
        "source_path_non_fungal = os.path.join(source_path, 'non_fungal')\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_fungal))} images of Fungal Infection.\")\n",
        "print(f\"There are {len(os.listdir(source_path_non_fungal))} images of Non Fungal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT-ZOxkQYPON",
        "outputId": "ff72617e-e3c2-425b-8776-97b3643086a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 88 images of Fungal Infection.\n",
            "There are 51 images of Non Fungal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define root directory\n",
        "root_dir = '/content/drive/MyDrive/Capstone/mencoba'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# GRADED FUNCTION: create_train_val_dirs\n",
        "def create_train_val_dirs(root_path):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "  \n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "  \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  os.makedirs(root_path)\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  val_dir = os.path.join(root_path, 'validation')\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "\n",
        "  train_cats_dir = os.path.join(train_dir, 'fungal')\n",
        "  train_dogs_dir = os.path.join(train_dir, 'nonfung')\n",
        "  val_cats_dir = os.path.join(val_dir, 'fungal')\n",
        "  val_dogs_dir = os.path.join(val_dir, 'nonfung')\n",
        "\n",
        "  os.makedirs(train_cats_dir)\n",
        "  os.makedirs(train_dogs_dir)\n",
        "  os.makedirs(val_cats_dir)\n",
        "  os.makedirs(val_dogs_dir)\n",
        "\n",
        "  pass\n",
        "  \n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "1PAkT7ZPTOhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your create_train_val_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60NkMtn-TtSH",
        "outputId": "e8e7a4e5-5e62-4178-a03b-7f9e8fd49896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Capstone/mencoba/training\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation\n",
            "/content/drive/MyDrive/Capstone/mencoba/training/fungal\n",
            "/content/drive/MyDrive/Capstone/mencoba/training/nonfung\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation/fungal\n",
            "/content/drive/MyDrive/Capstone/mencoba/validation/nonfung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to crop image\n",
        "# # note: the amount of croped pixels were approxed by me (nopal) \n",
        "# #       by measure the excess pixels\n",
        "# def crop_image(image):\n",
        "#     crop_width = 1920 - 170 - 160  # Calculate the resulting width after trimming\n",
        "#     crop_height = 1080  # Height remains the same\n",
        "#     crop_location = (170, 0)  # Starting position of the crop\n",
        "#     cropped_image = tf.image.crop(image, crop_location, [crop_height, crop_width])\n",
        "#     return cropped_image"
      ],
      "metadata": {
        "id": "p-M8YyTUZc21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def crop_image(image):\n",
        "#     crop_width = 1920 - 170 - 150  # Calculate the resulting width after trimming\n",
        "#     crop_height = 1080  # Height remains the same\n",
        "#     crop_location = (170, 0)  # Starting position of the crop\n",
        "\n",
        "#     # Crop the image using array indexing\n",
        "#     cropped_image = image[crop_location[1]:crop_location[1] + crop_height,\n",
        "#                           crop_location[0]:crop_location[0] + crop_width, :]\n",
        "\n",
        "#     return cropped_image"
      ],
      "metadata": {
        "id": "V18qe6fFZhGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # function to split dataset into training and validation\n",
        "# def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "#     files = os.listdir(SOURCE_DIR)\n",
        "\n",
        "#     verified_files = []\n",
        "#     for file in files:\n",
        "#         if os.path.getsize(os.path.join(SOURCE_DIR, file)) == 0:\n",
        "#             print(f\"{file} is zero length, so ignoring.\")\n",
        "#         else:\n",
        "#             verified_files.append(file)\n",
        "\n",
        "#     # Shuffle the files\n",
        "#     random.shuffle(verified_files)\n",
        "\n",
        "#     # Calculate the split index\n",
        "#     split_idx = int(SPLIT_SIZE * len(verified_files))\n",
        "\n",
        "#     # Split the files\n",
        "#     train_files = verified_files[:split_idx]\n",
        "#     val_files = verified_files[split_idx:]\n",
        "\n",
        "#     # Copy train files\n",
        "#     for file in train_files:\n",
        "#         src_path = os.path.join(SOURCE_DIR, file)\n",
        "#         dst_path = os.path.join(TRAINING_DIR, file)\n",
        "#         # Load the image using TensorFlow\n",
        "#         image = tf.io.read_file(src_path)\n",
        "#         image = tf.image.decode_image(image)\n",
        "#         # Crop the image\n",
        "#         cropped_image = crop_image(image)\n",
        "#         # Save the cropped image to the destination directory\n",
        "#         tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))\n",
        "\n",
        "#     # Copy validation files\n",
        "#     for file in val_files:\n",
        "#         src_path = os.path.join(SOURCE_DIR, file)\n",
        "#         dst_path = os.path.join(VALIDATION_DIR, file)\n",
        "#         # Load the image using TensorFlow\n",
        "#         image = tf.io.read_file(src_path)\n",
        "#         image = tf.image.decode_image(image)\n",
        "#         # Crop the image\n",
        "#         cropped_image = crop_image(image)\n",
        "#         # Save the cropped image to the destination directory\n",
        "#         tf.io.write_file(dst_path, tf.image.encode_png(cropped_image))"
      ],
      "metadata": {
        "id": "r9fFDRIIZtrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  ### START CODE HERE\n",
        "  file_list = []\n",
        "\n",
        "\n",
        "  for file in os.listdir(SOURCE_DIR):\n",
        "    file_path = os.path.join(SOURCE_DIR,file)\n",
        "    if(os.path.getsize(file_path) == 0):\n",
        "      print(file + \" is zero length, so ignoring.\")\n",
        "    else:\n",
        "      file_list.append(file_path)\n",
        "\n",
        "  train_num_items = int(round(len(file_list) * SPLIT_SIZE, 0))\n",
        "  train_list = random.sample(file_list, train_num_items)\n",
        "  val_list = list(set(file_list) - set(train_list))\n",
        "\n",
        "  for f in train_list:\n",
        "    copyfile(f,TRAINING_DIR+os.path.basename(f))\n",
        "  for f in val_list:\n",
        "    copyfile(f,VALIDATION_DIR+os.path.basename(f))\n",
        "\n",
        "  pass\n",
        "\n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "9oHwLZUxT3C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  file_list = []\n",
        "\n",
        "  for file in os.listdir(SOURCE_DIR):\n",
        "    file_path = os.path.join(SOURCE_DIR, file)\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "      print(file + \" is zero length, so ignoring.\")\n",
        "    else:\n",
        "      file_list.append(file_path)\n",
        "\n",
        "  random.shuffle(file_list)  # Shuffle the file list randomly\n",
        "\n",
        "  train_num_items = int(round(len(file_list) * SPLIT_SIZE, 0))\n",
        "  train_list = file_list[:train_num_items]\n",
        "  val_list = file_list[train_num_items:]\n",
        "\n",
        "  for f in train_list:\n",
        "    copyfile(f, TRAINING_DIR + os.path.basename(f))\n",
        "  for f in val_list:\n",
        "    copyfile(f, VALIDATION_DIR + os.path.basename(f))\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "9nYtNZrEEtrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "CAT_SOURCE_DIR = \"/content/drive/MyDrive/Capstone/Fungal V Non-Fungal/images_fungal\"\n",
        "DOG_SOURCE_DIR = \"/content/drive/MyDrive/Capstone/Fungal V Non-Fungal/non_fungal\"\n",
        "\n",
        "TRAINING_DIR = \"/content/drive/MyDrive/Capstone/mencoba/training\"\n",
        "VALIDATION_DIR = \"/content/drive/MyDrive/Capstone/mencoba/validation\"\n",
        "\n",
        "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"fungal/\")\n",
        "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"fungal/\")\n",
        "\n",
        "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"nonfung/\")\n",
        "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"nonfung/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .8\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal fungal directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
        "print(f\"Original healthy directory has {len(DOG_SOURCE_DIR)} images\\n\")\n",
        "\n",
        "# Training and validation splits\n",
        "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of fungal for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of healthy for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of fungal for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of healthy for validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taJ9ykn9T5JX",
        "outputId": "2e80fcce-5794-4506-98f6-3beba39ba275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original fungal directory has 88 images\n",
            "Original healthy directory has 62 images\n",
            "\n",
            "There are 70 images of fungal for training\n",
            "There are 41 images of healthy for training\n",
            "There are 18 images of fungal for validation\n",
            "There are 10 images of healthy for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  train_datagen = ImageDataGenerator(    \n",
        "    rescale=1.0/255.)\n",
        "    # rotation_range=10,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # shear_range=0.1,\n",
        "    # zoom_range=0.1,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode='nearest')\n",
        "    # rescale=1.0/255,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True,\n",
        "    # rotation_range=20,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=16,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(128, 128))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.)\n",
        "    # rotation_range=10,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1,\n",
        "    # shear_range=0.1,\n",
        "    # zoom_range=0.1,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(128, 128))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "sBZN_JC_UnKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPl2qpS4Uqkv",
        "outputId": "48c8efad-60d0-48c6-c2ef-63f031909b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 111 images belonging to 2 classes.\n",
            "Found 28 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba844313",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('accuracy') > 0.9 and logs.get('val_accuracy') > 0.9:\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2), \n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(), \n",
        "      # 512 neuron hidden layer\n",
        "      tf.keras.layers.Dense(512, activation='relu'), \n",
        "      # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cxOHZQipUuvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRDa7-8I7Jhu",
        "outputId": "7234b8ae-e8d5-43d6-d630-78f741cd1619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 126, 126, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 63, 63, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 61, 61, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 30, 30, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               2359808   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,457,761\n",
            "Trainable params: 2,457,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take a few epochs)\n",
        "model = create_model()\n",
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 50,\n",
        "                    verbose = 2,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-esmAoZ33c7",
        "outputId": "fbe82695-1ff4-493b-e820-1ad8ae8d6437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 - 8s - loss: 0.6299 - accuracy: 0.7117 - val_loss: 0.5151 - val_accuracy: 0.6429 - 8s/epoch - 1s/step\n",
            "Epoch 2/50\n",
            "7/7 - 7s - loss: 0.4252 - accuracy: 0.7928 - val_loss: 0.3054 - val_accuracy: 0.8929 - 7s/epoch - 965ms/step\n",
            "Epoch 3/50\n",
            "7/7 - 7s - loss: 0.4865 - accuracy: 0.8018 - val_loss: 0.3459 - val_accuracy: 0.8571 - 7s/epoch - 1s/step\n",
            "Epoch 4/50\n",
            "7/7 - 5s - loss: 0.3999 - accuracy: 0.8198 - val_loss: 0.3369 - val_accuracy: 0.8929 - 5s/epoch - 781ms/step\n",
            "Epoch 5/50\n",
            "7/7 - 7s - loss: 0.3243 - accuracy: 0.8649 - val_loss: 0.2910 - val_accuracy: 0.9286 - 7s/epoch - 1s/step\n",
            "Epoch 6/50\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "7/7 - 6s - loss: 0.2556 - accuracy: 0.9189 - val_loss: 0.2559 - val_accuracy: 0.9286 - 6s/epoch - 909ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracies for each epoch\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "5PHrd-Sq8g8N",
        "outputId": "559d2eeb-dca6-432f-b6a1-288147af5d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Save the trained model as a Keras HDF5 file. \n",
        "\n",
        "saved_model_path = \"./my_model.h5\"\n",
        "model.save(saved_model_path)\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "qadL93Qt86EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.2\n",
        "!pip install tensorflowjs\n",
        "import tensorflow as tf\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zKrerMAxHjYr",
        "outputId": "3719beba-1e26-4414-d7f5-2c024398c683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.2 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.2\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.6.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax<0.6.3,>=0.6.2 (from tensorflowjs)\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m189.9/189.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (5.12.0)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.10)\n",
            "Requirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.12.0)\n",
            "Collecting tensorflow-decision-forests>=1.3.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.13.0)\n",
            "Collecting packaging~=20.9 (from tensorflowjs)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.36)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (13.3.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (6.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (1.5.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.3.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.4.10+cuda11.cudnn86)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, packaging, flax, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.6.9\n",
            "    Uninstalling flax-0.6.9:\n",
            "      Successfully uninstalled flax-0.6.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flax-0.6.2 packaging-20.9 tensorflow-decision-forests-1.3.0 tensorflowjs-4.6.0 wurlitzer-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using TensorFlow Version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Use the tensorflow.js converter to convert the saved Keras model into JSON format.\n",
        "# YOUR CODE HERE\n",
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybrj_K89EKA",
        "outputId": "66b93044-30ea-4afb-8374-14230a338f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-09 17:05:17.114648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the filenames\n",
        "h5_file = \"./my_model.h5\"\n",
        "json_file = \"./model.json\"\n",
        "\n",
        "# Create a zip file\n",
        "zip_file_name = \"Fungal vs Non Fungal.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
        "    # Add the h5 file to the zip\n",
        "    zipf.write(h5_file, arcname='my_model.h5')\n",
        "\n",
        "    # Add the json file to the zip\n",
        "    zipf.write(json_file, arcname='model.json')\n",
        "\n",
        "print(\"Output files zipped successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcuvzyseBV0F",
        "outputId": "cae5c16a-1f68-4583-c3f2-695c6526b256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output files zipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the filenames\n",
        "h5_file = \"./my_model.h5\"\n",
        "json_file = \"./model.json\"\n",
        "bin_file1 = \"./group1-shard1of3.bin\"\n",
        "bin_file2 = \"./group1-shard2of3.bin\"\n",
        "bin_file3 = \"./group1-shard3of3.bin\"\n",
        "\n",
        "# Create a zip file\n",
        "zip_file_name = \"fungal vs non fung.zip\"\n",
        "with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
        "    # Add the h5 file to the zip\n",
        "    zipf.write(h5_file, arcname='my_model.h5')\n",
        "\n",
        "    # Add the json file to the zip\n",
        "    zipf.write(json_file, arcname='model.json')\n",
        "    \n",
        "    # Add the bin files to the zip\n",
        "    zipf.write(bin_file1, arcname='group1-shard1of3.bin')\n",
        "    zipf.write(bin_file2, arcname='group1-shard2of3.bin')\n",
        "    zipf.write(bin_file3, arcname='group1-shard3of3.bin')\n",
        "\n",
        "print(\"Output files zipped successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwR0JcJrIS5g",
        "outputId": "d6c9b94a-5f9b-4865-a767-e3f965f05ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output files zipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2), \n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(), \n",
        "      # 512 neuron hidden layer\n",
        "      tf.keras.layers.Dense(512, activation='relu'), \n",
        "      # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "68U-dL_HERVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRXSZ4WpE5EW",
        "outputId": "abbf4235-62f7-4f64-c679-640bc8b63bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.8026 - accuracy: 0.5946 - val_loss: 0.6582 - val_accuracy: 0.6429\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.6211 - accuracy: 0.6396 - val_loss: 0.5448 - val_accuracy: 0.7857\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.5450 - accuracy: 0.7748 - val_loss: 0.4371 - val_accuracy: 0.7500\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.4557 - accuracy: 0.8378 - val_loss: 0.3937 - val_accuracy: 0.8214\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.3216 - accuracy: 0.8919 - val_loss: 0.5124 - val_accuracy: 0.6429\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.3540 - accuracy: 0.8378 - val_loss: 0.4324 - val_accuracy: 0.7500\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.3335 - accuracy: 0.8739 - val_loss: 0.3482 - val_accuracy: 0.8214\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2386 - accuracy: 0.9279 - val_loss: 0.3469 - val_accuracy: 0.8571\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.2708 - accuracy: 0.9099 - val_loss: 0.3518 - val_accuracy: 0.8571\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.2038 - accuracy: 0.9459 - val_loss: 0.4505 - val_accuracy: 0.8571\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.2214 - accuracy: 0.9369 - val_loss: 0.5110 - val_accuracy: 0.8571\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2201 - accuracy: 0.9189 - val_loss: 0.3937 - val_accuracy: 0.8571\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.1876 - accuracy: 0.9459 - val_loss: 0.4983 - val_accuracy: 0.8571\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2102 - accuracy: 0.9369 - val_loss: 0.3802 - val_accuracy: 0.8571\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1586 - accuracy: 0.9459 - val_loss: 0.5912 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
      ],
      "metadata": {
        "id": "w_bQusmoWM1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Create a new model by adding your own classifier on top of the pre-trained ResNet model\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "AQciyQCZWVg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "LuZQ6-HjWcmR",
        "outputId": "3f7964a7-520f-4058-fb36-fa2cac03a243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 70s 7s/step - loss: 2.0308 - accuracy: 0.6937 - val_loss: 2025.8903 - val_accuracy: 0.6429\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 44s 6s/step - loss: 0.2158 - accuracy: 0.9189 - val_loss: 143049.0156 - val_accuracy: 0.6429\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 43s 6s/step - loss: 0.2387 - accuracy: 0.9459 - val_loss: 532021.9375 - val_accuracy: 0.6429\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 47s 7s/step - loss: 0.1038 - accuracy: 0.9640 - val_loss: 515740.7812 - val_accuracy: 0.6429\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 44s 6s/step - loss: 0.1261 - accuracy: 0.9910 - val_loss: 254101.0938 - val_accuracy: 0.6429\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 46s 6s/step - loss: 0.2518 - accuracy: 0.9459 - val_loss: 105589.9453 - val_accuracy: 0.6429\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9910"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f1e6b0f8bc58>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Initialize the Pretrained Model\n",
        "feature_extractor = ResNet50(weights='imagenet', \n",
        "                             input_shape=(128, 128, 3),\n",
        "                             include_top=False)\n",
        "\n",
        "# Set this parameter to make sure it's not being trained\n",
        "feature_extractor.trainable = False\n",
        "\n",
        "# Set the input layer\n",
        "input_ = tf.keras.Input(shape=(128, 128, 3))\n",
        "\n",
        "# Set the feature extractor layer\n",
        "x = feature_extractor(input_, training=False)\n",
        "\n",
        "# Set the pooling layer\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Set the final layer with sigmoid activation function\n",
        "output_ = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model object\n",
        "model = tf.keras.Model(input_, output_)\n",
        "\n",
        "# Compile it\n",
        "model.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Print The Summary of The Model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edlbXJQLG9g4",
        "outputId": "47dce562-0008-4e0c-caf6-cfd9350d87e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,589,761\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs=15, validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L_WcSk1HOag",
        "outputId": "583d0d00-16d7-43dc-de75-bed125dec38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - 20s 2s/step - loss: 0.7754 - accuracy: 0.3694 - val_loss: 0.7306 - val_accuracy: 0.3571\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.7080 - accuracy: 0.4234 - val_loss: 0.6729 - val_accuracy: 0.6429\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 16s 2s/step - loss: 0.6656 - accuracy: 0.6306 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6527 - accuracy: 0.6306 - val_loss: 0.6462 - val_accuracy: 0.6429\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6509 - accuracy: 0.6306 - val_loss: 0.6445 - val_accuracy: 0.6429\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6506 - accuracy: 0.6306 - val_loss: 0.6429 - val_accuracy: 0.6429\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 15s 2s/step - loss: 0.6466 - accuracy: 0.6306 - val_loss: 0.6403 - val_accuracy: 0.6429\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 18s 2s/step - loss: 0.6428 - accuracy: 0.6306 - val_loss: 0.6383 - val_accuracy: 0.6429\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6401 - accuracy: 0.6306 - val_loss: 0.6370 - val_accuracy: 0.6429\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6382 - accuracy: 0.6306 - val_loss: 0.6361 - val_accuracy: 0.6429\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 17s 2s/step - loss: 0.6345 - accuracy: 0.6306 - val_loss: 0.6336 - val_accuracy: 0.6429\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6319 - accuracy: 0.6306 - val_loss: 0.6311 - val_accuracy: 0.6429\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 17s 2s/step - loss: 0.6293 - accuracy: 0.6306 - val_loss: 0.6295 - val_accuracy: 0.6429\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 16s 2s/step - loss: 0.6257 - accuracy: 0.6306 - val_loss: 0.6273 - val_accuracy: 0.6429\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.6234 - accuracy: 0.6306 - val_loss: 0.6250 - val_accuracy: 0.6429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f806a683040>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}